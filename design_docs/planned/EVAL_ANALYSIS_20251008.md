# AI Eval Analysis Summary

**Generated**: 2025-10-08 15:02:55
**Model**: gpt5

## Overview

- **Total Runs**: 78
- **Failures**: 34
- **Success Rate**: 56.4%
- **Issues Identified**: 5

## Issues by Impact

### Critical (1)

- **AILANG: Compilation Failures** (ailang, 12 failures)
  - Benchmarks: adt_option, fizzbuzz, json_parse, pipeline, records_person

### High (2)

- **PYTHON: Runtime Errors** (python, 9 failures)
  - Benchmarks: fizzbuzz, records_person, recursion_factorial
- **AILANG: Runtime Errors** (ailang, 7 failures)
  - Benchmarks: adt_option, fizzbuzz

### Low (2)

- **: ** (, 3 failures)
  - Benchmarks: 
- **PYTHON: Logic Errors in fizzbuzz, pipeline** (python, 2 failures)
  - Benchmarks: fizzbuzz, pipeline

## Generated Design Documents

- [20251008___.md](design_docs/planned/20251008___.md)
- [20251008_logic_error_python_logic_errors_in_fizzbuzz_pipeline.md](design_docs/planned/20251008_logic_error_python_logic_errors_in_fizzbuzz_pipeline.md)

## Next Steps

1. Review generated design documents
2. Adjust priorities and estimates as needed
3. Move approved designs to milestone tracking
4. Create implementation branches
5. Re-run eval suite after fixes to measure improvement

---

*Generated by `ailang eval-analyze`*
